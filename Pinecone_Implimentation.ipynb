{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CYa4LfRsBbM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf64d40-3324-4d82-fc9c-b8996cd15beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "4WfHTN6CC72l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f45bf7a-e637-4ca4-e50d-ebfef650d66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.15)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "json_path = \"/content/drive/MyDrive/Fundus/EyePACS/kaggle.json\"\n",
        "f = open(json_path, 'r')\n",
        "kaggle_details = json.load(f)\n",
        "f.close()\n",
        "kaggle_user = kaggle_details[\"username\"]\n",
        "kaggle_key = kaggle_details[\"key\"]"
      ],
      "metadata": {
        "id": "9fyVyKBpDf1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export KAGGLE_USERNAME=kaggle_user\n",
        "!export KAGGLE_KEY=kaggle_key"
      ],
      "metadata": {
        "id": "xgDw0MVvDEHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awh8rwA1aSW6",
        "outputId": "f8e4544a-124e-4c68-b456-d03e7b51819d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf3b3YW2aanS",
        "outputId": "ffd7426c-b7ac-4299-dac8-27a8cbed1923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Fundus/EyePACS/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "50b5Sj9Aa3u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "kZUCEcIKbb4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Fundus/\n",
        "!ls"
      ],
      "metadata": {
        "id": "7To8MJnqFQNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5558f24e-4fd8-4b88-8032-374169c211ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Fundus\n",
            "DeepDRiD  EyePACS  messidor_densenet_full_best.zip  Models  Pickles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EyePACS"
      ],
      "metadata": {
        "id": "pH1EXbsYF_9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67213b76-5c27-42a9-8609-da6dc0ddfaae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Fundus/EyePACS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download diabetic-retinopathy-detection -f train.zip.005.zip"
      ],
      "metadata": {
        "id": "Z6-wevBuFQ3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6171b5b-b87f-4571-d7f1-6a276f312cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404 - Not Found - Not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "0p7xCljZFtXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4934b97b-1d0f-4594-df98-9163e7950c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXT-lCgmmwl7",
        "outputId": "de8df464-ab5f-4a77-be1c-bb676c9b5d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KOUy-W0AyO1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = 'cuda' if use_cuda else 'cpu'"
      ],
      "metadata": {
        "id": "z3i3GhJJwNqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_file_paths(path, base_path, image_path_postfix):\n",
        "  df = pd.read_csv(path)\n",
        "  image_id_list, image_path_list, eye_lvl_list = list(df[\"image_id\"]), list(df[\"image_path\"]), list(df[\"eye_DR_Level\"])\n",
        "  image_path_list = [s.replace('\\\\', '/') for s in image_path_list]\n",
        "\n",
        "  image_path_list_final = []\n",
        "  for s in image_path_list:\n",
        "    splits = s.split('/')\n",
        "    sf = '/' + splits[1] + '/' + image_path_postfix\n",
        "    postfix = '/'.join(splits[2:])\n",
        "    sf = sf + '/' + postfix\n",
        "    image_path_list_final.append(sf)\n",
        "\n",
        "  file_paths = [(image_id_list[i], base_path + image_path_list_final[i], eye_lvl_list[i]) for i in range(len(image_id_list))]\n",
        "  return file_paths"
      ],
      "metadata": {
        "id": "rOs6gA3XHDVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batches(list_obj, batch_size):\n",
        "  j = 0\n",
        "  i = batch_size\n",
        "  if i > len(list_obj):\n",
        "    return [list_obj]\n",
        "  toret = []\n",
        "  for i in range(batch_size, len(list_obj), batch_size):\n",
        "    toret.append(list_obj[j : i])\n",
        "    j = i\n",
        "  return toret"
      ],
      "metadata": {
        "id": "Qpe_NhHZc-Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/Fundus\""
      ],
      "metadata": {
        "id": "7UgmWFOhabUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/Fundus\"\n",
        "ckpt_path = base_path + '/EyePACS/resnet50_128_08.pt'\n",
        "\n",
        "weights = torch.load(ckpt_path)\n",
        "model = models.resnet50()\n",
        "# Weights of fully connected layer are removed in the file, so set strict to be False.\n",
        "model.load_state_dict(weights, strict=False)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "CB6MWoe4GKaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64800af6-2771-4274-916c-56eb9cf86e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "ejSghaMkw67B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drid_path = base_path + \"/DeepDRiD\"\n",
        "train_csv_path = drid_path + \"/training_data.csv\"\n",
        "valid_csv_path = drid_path + \"/validation_data.csv\"\n",
        "image_path_prefix = \"Images\"\n",
        "\n",
        "file_items_train = get_file_paths(train_csv_path, drid_path, image_path_prefix)\n",
        "file_items_valid = get_file_paths(valid_csv_path, drid_path, image_path_prefix)\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "#train_paths_batched = make_batches(file_items_train, batch_size)\n",
        "#valid_paths_batched = make_batches(file_items_valid, batch_size)"
      ],
      "metadata": {
        "id": "zwJOqxvFG2nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit = get_file_paths(train_csv_path, drid_path, image_path_prefix)\n",
        "print(fit == file_items_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6xUpQWwapiy",
        "outputId": "4a35d59a-7eac-44f9-d50f-d8ffc14972a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(file_items_train))\n",
        "print(file_items_train[:3])\n",
        "print(len(file_items_valid))\n",
        "\n",
        "file_paths_train = [i[1] for i in file_items_train]\n",
        "file_paths_valid = [i[1] for i in file_items_valid]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpy7sz2Woz9z",
        "outputId": "ad563480-0e77-4610-9222-d676faf0bb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "578\n",
            "[('5_l1', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/5/5_l1.jpg', 0), ('5_l2', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/5/5_l2.jpg', 0), ('7_l2', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/7/7_l2.jpg', 0)]\n",
            "58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "SaJijxoCpxjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_transform(pattern):\n",
        "  tsfm = transforms.Resize((512, 512))\n",
        "  # add a step here to remove 10 % of the border. See if it is needed with this dataset.\n",
        "  pattern= (pattern-np.min(pattern))/(np.max(pattern)-np.min(pattern))\n",
        "  pattern=np.moveaxis(pattern,2,0)\n",
        " #pattern=np.expand_dims(pattern, axis=0)\n",
        "  pattern_tensor=torch.from_numpy(pattern).float()\n",
        "  pattern_tensor = tsfm(pattern_tensor)\n",
        "  return pattern_tensor"
      ],
      "metadata": {
        "id": "Qqmt1R2sMT8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "w5T0TgmsXgtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def resnet_features(model,pattern, tsfm):\n",
        "#   pattern= (pattern-np.min(pattern))/(np.max(pattern)-np.min(pattern))\n",
        "#   pattern=np.moveaxis(pattern,2,0)\n",
        "#   pattern=np.expand_dims(pattern, axis=0)\n",
        "#   pattern_tensor=torch.from_numpy(pattern).float()\n",
        "#   pattern_tensor = tsfm(pattern_tensor)\n",
        "#   pattern_out=model(pattern_tensor).detach().numpy()[0,:]\n",
        "#   pattern_out = np.hstack(pattern_out)\n",
        "#   pattern_out = np.hstack(pattern_out)\n",
        "\n",
        "#   return pattern_out"
      ],
      "metadata": {
        "id": "OpEar2AShftt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InferDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, pil_imgs):\n",
        "        super(InferDataset, self,).__init__()\n",
        "\n",
        "        self.pil_imgs = pil_imgs\n",
        "        self.transform = make_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pil_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.pil_imgs[idx]\n",
        "\n",
        "        return self.transform(img)"
      ],
      "metadata": {
        "id": "-Sw_4Hw8lzYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "pil_imgs_train = [np.array(Image.open(path)) for path in file_paths_train]\n",
        "train_data = InferDataset(pil_imgs_train)\n",
        "\n",
        "del pil_imgs_train\n",
        "gc.collect()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=4,\n",
        "                                          pin_memory=True)\n",
        "\n",
        "del train_data\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Dl1VUz2VjDrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8a2fbf-9489-482f-e185-67b0d1f96c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patterns = []\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    data = data.to(device)\n",
        "    pattern_out = model(data)\n",
        "    pattern_out = pattern_out.cpu().numpy()\n",
        "    patterns.append(pattern_out)"
      ],
      "metadata": {
        "id": "66DLXJKWpoeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8bee2a-d270-4adc-a1a2-6ff81f85c324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del train_loader\n",
        "gc.collect()\n",
        "\n",
        "patterns = np.vstack(patterns)"
      ],
      "metadata": {
        "id": "LvPbV_nwbORz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "2fd9fa25-138a-4bd7-81e7-804c44573812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3639f3f44f00>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(patterns.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWbNNCIKqnyc",
        "outputId": "91927a85-2cdd-4e0c-c448-cce3d0001e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(578, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(drid_path + '/train_patterns.npy', patterns)"
      ],
      "metadata": {
        "id": "dfQTbQLrpR-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pil_imgs_valid = [np.array(Image.open(path)) for path in file_paths_valid]\n",
        "valid_data = InferDataset(pil_imgs_valid)\n",
        "\n",
        "del pil_imgs_valid\n",
        "gc.collect()\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=1,\n",
        "                                          pin_memory=True)\n",
        "\n",
        "del valid_data\n",
        "gc.collect()\n",
        "\n",
        "patterns = []\n",
        "with torch.no_grad():\n",
        "  for data in valid_loader:\n",
        "    data = data.to(device)\n",
        "    pattern_out = model(data)\n",
        "    pattern_out = pattern_out.cpu().numpy()\n",
        "    patterns.append(pattern_out)\n",
        "\n",
        "del valid_loader\n",
        "gc.collect()\n",
        "\n",
        "patterns = np.vstack(patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F96O25Brq9As",
        "outputId": "6c605853-9007-416a-c2da-ae55adaf8590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(patterns.shape)\n",
        "np.save(drid_path + '/valid_patterns.npy', patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8TbMglNrOrB",
        "outputId": "10a84eb8-2d36-46ee-eb3d-61ed32cd58a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(58, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making Database\n",
        "The data to be upserted should be in following format: CIFAR100.123, [4.237038612365723, 11.179943084716797, 1.3662679195404053], {'label': 'orange'}, i.e. id, embedding, label\n",
        "\n"
      ],
      "metadata": {
        "id": "woJdZi4IXfw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNFfXLQibdQx",
        "outputId": "0fecb0a5-577a-44e4-d066-752fdac174ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-2.2.2-py3-none-any.whl (179 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.6.3)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/283.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.26.16)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
            "Installing collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.3.0 loguru-0.7.0 pinecone-client-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "import tqdm\n",
        "import httpimport\n",
        "import pinecone\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "iq-xtLYbKi8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815f41ed-8985-4952-df98-89697c95673d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PINECONE_EXAMPLE_API_KEY\"] = \"5d09425a-8d43-4833-8d44-9113d452c3ed\""
      ],
      "metadata": {
        "id": "2hVMIPosdA7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIRECTORY = 'tmp'\n",
        "INDEX_NAME = 'image-search'\n",
        "INDEX_DIMENSION = 1000\n",
        "BATCH_SIZE=20"
      ],
      "metadata": {
        "id": "4jcbEJ60XipL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(os.environ[\"PINECONE_EXAMPLE_API_KEY\"], environment='us-west1-gcp-free')\n",
        "\n",
        "# if INDEX_NAME not in pinecone.list_indexes():\n",
        "#     pinecone.create_index(name=INDEX_NAME, dimension=INDEX_DIMENSION)\n",
        "\n",
        "index = pinecone.Index(INDEX_NAME)"
      ],
      "metadata": {
        "id": "_jEigNduXo47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_path = drid_path + \"/train_patterns.npy\"\n",
        "train_ds = np.load(train_dataset_path)\n",
        "print(train_ds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK6kZkLMYIfn",
        "outputId": "a636d597-bff2-46f5-eb9d-c71ca06b354b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(578, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l_obj = []\n",
        "for i in range(len(file_items_train)):\n",
        "  embedding = train_ds[i]\n",
        "  embedding = embedding.tolist()\n",
        "  id = file_items_train[i][0]\n",
        "  label = file_items_train[i][2]\n",
        "  l_obj.append((id, embedding, {'label' : label}))\n",
        "\n",
        "batches = make_batches(l_obj, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "hhJ5f1cmfTBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(batches))\n",
        "print(len(batches[0]))\n",
        "#print(batches[0])\n",
        "b = batches[0][0]\n",
        "print(len(b), type(b))\n",
        "nda = b[1]\n",
        "print(len(nda))\n",
        "print(type(nda))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPVhu_j1iFOV",
        "outputId": "445cec7c-dca1-4322-9646-52bd463dcd64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n",
            "20\n",
            "3 <class 'tuple'>\n",
            "1000\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in tqdm.tqdm(batches):\n",
        "  index.upsert(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8daEY-mhpLx",
        "outputId": "9053f6ac-c95f-4b2f-dbe5-de47b59a2b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28/28 [00:02<00:00, 10.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset_path = drid_path + '/valid_patterns.npy'\n",
        "valid_ds = np.load(valid_dataset_path)\n",
        "print(valid_ds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCtXvUCM4h-I",
        "outputId": "dce4aeee-ec49-4077-d177-18b601e05a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(58, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = valid_ds[0].tolist()\n",
        "response = index.query(q1, top_k=4, include_metadata=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTuKcb-n5mVq",
        "outputId": "c23b80d3-e8f8-4812-88c4-6e7ceaf93283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'matches': [{'id': '286_r2',\n",
            "              'metadata': {'label': 0.0},\n",
            "              'score': 0.909316182,\n",
            "              'values': []},\n",
            "             {'id': '392_r1',\n",
            "              'metadata': {'label': 0.0},\n",
            "              'score': 0.89951539,\n",
            "              'values': []},\n",
            "             {'id': '7_l2',\n",
            "              'metadata': {'label': 0.0},\n",
            "              'score': 0.89802587,\n",
            "              'values': []},\n",
            "             {'id': '188_r1',\n",
            "              'metadata': {'label': 0.0},\n",
            "              'score': 0.891475,\n",
            "              'values': []}],\n",
            " 'namespace': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_items_valid[0][2])\n",
        "print(type(file_items_valid[0][2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi1nEagP6ESw",
        "outputId": "d85f4436-1f6a-4ffc-b49d-6591cf5975c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to have accuracy and F1 score using confusion matrix for above. Using top-1, max-5, mindist-5, and top-5. Also need to make ROC-AUC. If good results obtained, then this is awesome, and needs to be taken to further production. Results also need to be visualized. The exact ANN used also needs to be known."
      ],
      "metadata": {
        "id": "G0mtKDJt6Swb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "afId50sF6vS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_1 = []\n",
        "top_5 = []\n",
        "top_1_ids = []\n",
        "top_5_ids = []\n",
        "\n",
        "nbr_ids = []\n",
        "nbr_labels = []\n",
        "nbr_scores = []\n",
        "\n",
        "for i in range(len(valid_ds)):\n",
        "  q = valid_ds[i].tolist()\n",
        "  resp = index.query(q, top_k = 5, include_metadata = True)\n",
        "  nbrs_list = resp[\"matches\"]\n",
        "  top_1.append(int(nbrs_list[0][\"metadata\"][\"label\"]))\n",
        "  top_1_ids.append(nbrs_list[0][\"id\"])\n",
        "\n",
        "  gnd_val = file_items_valid[i][2]\n",
        "  top_5_flag = True\n",
        "\n",
        "  for nbr in nbrs_list:\n",
        "    if top_5_flag and int(nbr[\"metadata\"][\"label\"]) == gnd_val:\n",
        "      top_5.append(int(nbr[\"metadata\"][\"label\"]))\n",
        "      top_5_ids.append(nbr[\"id\"])\n",
        "      top_5_flag = False\n",
        "    tmp_labels.append(int(nbr[\"metadata\"][\"label\"]))\n",
        "    tmp_ids.append(nbr[\"id\"])\n",
        "    tmp_scores.append(nbr[\"score\"])\n",
        "\n",
        "  nbr_labels.append(tmp_labels)\n",
        "  nbr_ids.append(tmp_ids)\n",
        "  nbr_scores.append(tmp_scores)\n",
        "\n",
        "gnd_items = [file_items_valid[i][2] for i in range(len(file_items_valid))]"
      ],
      "metadata": {
        "id": "1EKyD1DFjUS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(gnd_items, top_1, digits = 4)"
      ],
      "metadata": {
        "id": "n5weV_gFnDJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(gnd_items, top_5, digits = 4)"
      ],
      "metadata": {
        "id": "2K04V9zaooiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcGini(arr, classes):\n",
        "  cd = {}\n",
        "  for c in classes:\n",
        "    cd[c] = 0\n",
        "  for elt in arr:\n",
        "    cd[elt] += 1\n",
        "  tot = len(arr)\n",
        "  sqsum = 0\n",
        "  for c in cd:\n",
        "    sqsum += (cd[c]/tot)**2\n",
        "  return 2*(1 - sqsum)"
      ],
      "metadata": {
        "id": "VlOhMbAfpD3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 1e-6\n",
        "classes = [0,1,2,3,4]\n",
        "inv_ginis = [1/(calcGini(grp, classes) + eta) for grp in nbr_labels]"
      ],
      "metadata": {
        "id": "kVLjIjX5_Z6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list = [int(top_5[i] == gnd_items[i]) for i in range(len(gnd_items))]\n",
        "weighted_acc_list = [acc_list[i] * inv_ginis[i] for i in range(len(acc_list)]\n",
        "print(weighted_acc_list[:10])"
      ],
      "metadata": {
        "id": "qdmC9xmFAyqr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}