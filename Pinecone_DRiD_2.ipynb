{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEON6BQoMyG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60761fa6-d4be-43e9-9c22-3dc09ca9443f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torchvision import transforms as tt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "L23qHMXBiMp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "Y-ZQs8VVgma4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = 'cuda' if use_cuda else 'cpu'"
      ],
      "metadata": {
        "id": "iUzHTEhAgRif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_file_paths(path, base_path, image_path_postfix, data_type = \"Train\"):\n",
        "  df = pd.read_csv(path)\n",
        "  image_id_list, image_path_list, eye_lvl_list = list(df[\"image_id\"]), list(df[\"image_path\"]), list(df[\"eye_DR_Level\"])\n",
        "  image_path_list = [s.replace('\\\\', '/') for s in image_path_list]\n",
        "\n",
        "  image_path_list_final = []\n",
        "  for s in image_path_list:\n",
        "    splits = s.split('/')\n",
        "    sf = '/' + splits[1] + '/' + image_path_postfix\n",
        "    postfix = '/'.join(splits[2:])\n",
        "    sf = sf + '/' + postfix\n",
        "    image_path_list_final.append(sf)\n",
        "\n",
        "  if data_type == \"Train\":\n",
        "    n = len(image_path_list)\n",
        "    counts = [0 for i in range(5)]\n",
        "    thresh = 150 # max(counts)\n",
        "    for it in eye_lvl_list:\n",
        "      counts[it] += 1 #\n",
        "\n",
        "    diff = [max(thresh, counts[i]) - counts[i] for i in range(len(counts))]\n",
        "    make_per_image = [max(1,diff[i]//counts[i]) for i in range(len(counts))]\n",
        "\n",
        "    image_id_list_final, image_path_list_train, eye_lvl_list_final = [], [], []\n",
        "\n",
        "    for i in range(n):\n",
        "      # Impliment early stopping as well\n",
        "      to_make = make_per_image[eye_lvl_list[i]]\n",
        "      d = diff[eye_lvl_list[i]]\n",
        "      image_id_list_final.append(image_id_list[i])\n",
        "      image_path_list_train.append(image_path_list_final[i])\n",
        "      eye_lvl_list_final.append(eye_lvl_list[i])\n",
        "\n",
        "      if d > 0:\n",
        "        if d < to_make:\n",
        "          to_make = 1\n",
        "        d -= 1\n",
        "        for j in range(to_make):\n",
        "          image_path_list_train.append(image_path_list_final[i])\n",
        "          eye_lvl_list_final.append(eye_lvl_list[i])\n",
        "          name = image_id_list[i].split('.')[0]\n",
        "          name += \"_{}.jpg\".format(j+1)\n",
        "          image_id_list_final.append(name)\n",
        "\n",
        "        diff[eye_lvl_list[i]] = d\n",
        "    file_paths = [(image_id_list_final[i], base_path + image_path_list_train[i], eye_lvl_list_final[i]) for i in range(len(image_id_list_final))]\n",
        "\n",
        "  else:\n",
        "    file_paths = [(image_id_list[i], base_path + image_path_list_final[i], eye_lvl_list[i]) for i in range(len(image_path_list_final))]\n",
        "  return file_paths"
      ],
      "metadata": {
        "id": "6F67GRBYMj7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_transform(pattern, flag):\n",
        "  random.seed(0)\n",
        "  tsfm = tt.RandomChoice(\n",
        "                  [tt.RandomHorizontalFlip(),\n",
        "                  tt.RandomVerticalFlip(),\n",
        "                  tt.RandomRotation(30)\n",
        "                  ]\n",
        "                )\n",
        "  pattern = (pattern - np.min(pattern))/(np.max(pattern) - np.min(pattern))\n",
        "  pattern = np.moveaxis(pattern,2,0)\n",
        "  pattern_tensor = torch.from_numpy(pattern).float()\n",
        "  pattern_tensor = tt.Resize((512, 512))(pattern_tensor)\n",
        "  if flag:\n",
        "    pattern_tensor = tsfm(pattern_tensor)\n",
        "  return pattern_tensor"
      ],
      "metadata": {
        "id": "N3bmwHYYFnqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, file_paths, file_ids):\n",
        "        super(EmbeddingDataset, self,).__init__()\n",
        "\n",
        "        self.file_paths = file_paths\n",
        "        self.transform = make_transform\n",
        "        self.file_ids = file_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = np.array(Image.open(self.file_paths[idx]))\n",
        "        n = len(self.file_ids[idx].split('_'))\n",
        "        aug_flag = False\n",
        "        if n == 3:\n",
        "          aug_flag = True\n",
        "        return self.transform(img, aug_flag)"
      ],
      "metadata": {
        "id": "VeIqzJfZiM8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/Fundus\""
      ],
      "metadata": {
        "id": "RMLpc2yKhTqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drid_path = base_path + \"/DeepDRiD\"\n",
        "train_csv_path = drid_path + \"/training_data.csv\"\n",
        "valid_csv_path = drid_path + \"/validation_data.csv\"\n",
        "image_path_prefix = \"Images\"\n"
      ],
      "metadata": {
        "id": "r4OxuAUAgsD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_items_train = get_file_paths(train_csv_path, drid_path, image_path_prefix)"
      ],
      "metadata": {
        "id": "rAyk6l9Wg2W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(file_items_train))\n",
        "print(file_items_train[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2JZAI4gnQn0",
        "outputId": "806a73d5-cbcf-447d-e4b9-676f362efaf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "806\n",
            "[('5_l1', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/5/5_l1.jpg', 0), ('5_l2', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/5/5_l2.jpg', 0), ('7_l2', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/7/7_l2.jpg', 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_items_train[300:311])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2I6tGSNohO0",
        "outputId": "18670cc4-8865-423c-8bc7-08bb01dfd8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('207_l1_1.jpg', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/207/207_l1.jpg', 1), ('215_l1', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/215/215_l1.jpg', 1), ('215_l1_1.jpg', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/215/215_l1.jpg', 1), ('226_l1', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/226/226_l1.jpg', 1), ('226_l1_1.jpg', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/226/226_l1.jpg', 1), ('226_l2', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/226/226_l2.jpg', 1), ('226_l2_1.jpg', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/226/226_l2.jpg', 1), ('278_l2', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/278/278_l2.jpg', 1), ('278_l2_1.jpg', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/278/278_l2.jpg', 1), ('282_r1', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/282/282_r1.jpg', 1), ('282_r1_1.jpg', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/282/282_r1.jpg', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_items_valid = get_file_paths(valid_csv_path, drid_path, image_path_prefix, data_type = \"Valid\")\n",
        "\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "F4x2_SUlnLk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(file_items_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfCiEWaznZLr",
        "outputId": "9a8f79a3-4f97-41d1-ab88-6abff7669e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths_train = [i[1] for i in file_items_train]\n",
        "file_ids_train = [i[0] for i in file_items_train]\n",
        "\n",
        "file_paths_valid = [i[1] for i in file_items_valid]\n",
        "file_ids_valid = [i[0] for i in file_items_valid]"
      ],
      "metadata": {
        "id": "if_451QPqq3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(file_ids_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIWZb_Ew_iJg",
        "outputId": "7344136e-03ea-4da8-ad64-beea4dab02f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = base_path + '/EyePACS/resnet50_128_08.pt'\n",
        "\n",
        "weights = torch.load(ckpt_path)\n",
        "model = models.resnet50()\n",
        "# Weights of fully connected layer are removed in the file, so set strict to be False.\n",
        "model.load_state_dict(weights, strict=False)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISoMr4vvqVYS",
        "outputId": "f5c05221-2aea-42ba-e4f4-5d7b1fb3fa0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "lJdnDEhWqWLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = EmbeddingDataset(file_paths_train, file_ids_train)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=2,\n",
        "                                          pin_memory=True)\n",
        "\n",
        "del train_data\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bMfznUkqcYD",
        "outputId": "54057421-46c6-42ae-d893-d7d16d0b7c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "138"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patterns = []\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    data = data.to(device)\n",
        "    pattern_out = model(data)\n",
        "    pattern_out = pattern_out.cpu().numpy()\n",
        "    patterns.append(pattern_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y89ByTFqtzFg",
        "outputId": "84fd0540-2adf-4622-f1ea-24c9692acde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(patterns))\n",
        "print(len(patterns[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYJVex9l_Vxv",
        "outputId": "4b38dc60-6b07-428e-dedc-b63e0ff08442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del train_loader\n",
        "gc.collect()\n",
        "\n",
        "patterns = np.vstack(patterns)"
      ],
      "metadata": {
        "id": "3Lac0oRAt3Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(patterns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-57sDvFyAEmS",
        "outputId": "875d8311-2b7f-4a92-a5da-20d0f55856bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(patterns.shape)"
      ],
      "metadata": {
        "id": "TA_FGP2DuGoH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb6342e-3622-4df9-8230-b1576686f407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(806, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(drid_path + '/train_patterns_augmented.npy', patterns)"
      ],
      "metadata": {
        "id": "E0utoWXFuPI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DBQaowcbW98",
        "outputId": "0c5e981f-33a7-4e5a-ec41-922d4ebc69b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-2.2.2-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0.1)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.7.1)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Downloading dnspython-2.4.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.26.16)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.22.4)\n",
            "Collecting httpcore>=0.17.3 (from dnspython>=2.0.0->pinecone-client)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio<2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from dnspython>=2.0.0->pinecone-client) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore>=0.17.3->dnspython>=2.0.0->pinecone-client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore>=0.17.3->dnspython>=2.0.0->pinecone-client) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore>=0.17.3->dnspython>=2.0.0->pinecone-client) (1.1.2)\n",
            "Installing collected packages: loguru, h11, httpcore, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.4.0 h11-0.14.0 httpcore-0.17.3 loguru-0.7.0 pinecone-client-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "import tqdm\n",
        "import httpimport\n",
        "import pinecone\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht1pkQz9bX7G",
        "outputId": "16e9ab2d-4dfc-492a-c7be-1a2034e4b1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PINECONE_EXAMPLE_API_KEY\"] = \"5d09425a-8d43-4833-8d44-9113d452c3ed\""
      ],
      "metadata": {
        "id": "vGo0VuBobjVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIRECTORY = 'pinecone'\n",
        "INDEX_NAME = 'aug-1'\n",
        "INDEX_DIMENSION = 1000\n",
        "BATCH_SIZE=20"
      ],
      "metadata": {
        "id": "eqh6_6yBbnMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(os.environ[\"PINECONE_EXAMPLE_API_KEY\"], environment='us-west1-gcp-free')\n",
        "\n",
        "if INDEX_NAME not in pinecone.list_indexes():\n",
        "  pinecone.create_index(name=INDEX_NAME, dimension=INDEX_DIMENSION)\n",
        "\n",
        "index = pinecone.Index(INDEX_NAME)"
      ],
      "metadata": {
        "id": "6TaXy4ZobqGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/Fundus\"\n",
        "drid_path = base_path + \"/DeepDRiD\""
      ],
      "metadata": {
        "id": "pWRbPg5tpaPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_path = drid_path + \"/train_patterns_augmented.npy\"\n",
        "train_ds = np.load(train_dataset_path)\n",
        "print(train_ds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UaXfn6Fb52E",
        "outputId": "47a4d7b6-1d6e-45e1-fcd9-6cde9b35cd1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(806, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batches(list_obj, batch_size):\n",
        "  j = 0\n",
        "  i = batch_size\n",
        "  if i > len(list_obj):\n",
        "    return [list_obj]\n",
        "  toret = []\n",
        "  for i in range(batch_size, len(list_obj), batch_size):\n",
        "    toret.append(list_obj[j : i])\n",
        "    j = i\n",
        "  return toret"
      ],
      "metadata": {
        "id": "UpIGCbE-sCzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_obj = []\n",
        "for i in range(len(file_items_train)):\n",
        "  embedding = train_ds[i]\n",
        "  embedding = embedding.tolist()\n",
        "  id = file_items_train[i][0]\n",
        "  label = file_items_train[i][2]\n",
        "  l_obj.append((id, embedding, {'label' : label}))\n",
        "\n",
        "batches = make_batches(l_obj, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "FbfXpoXJb_cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(batches))\n",
        "print(len(batches[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1SWJAyiqoXX",
        "outputId": "3082bd21-800c-4255-d20e-6c0528cef3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in tqdm.tqdm(batches):\n",
        "  index.upsert(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ysp2oBcfnpzF",
        "outputId": "de52b762-eebf-4f95-b11e-585a3e9c46b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset_path = drid_path + '/valid_patterns.npy'\n",
        "valid_ds = np.load(valid_dataset_path)\n",
        "print(valid_ds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzj2gtM1nz3g",
        "outputId": "94a448aa-a5b6-4d4a-8c81-5a440d788078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(58, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = valid_ds[0].tolist()\n",
        "response = index.query(q1, top_k=5, include_metadata=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLA0GASan3RQ",
        "outputId": "e268127c-405f-4409-efb3-96c1f8115040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'matches': [{'id': '20_l2',\n",
            "              'metadata': {'label': 0.0},\n",
            "              'score': 0.0917797163,\n",
            "              'values': []},\n",
            "             {'id': '272_l2',\n",
            "              'metadata': {'label': 0.0},\n",
            "              'score': 0.0846818462,\n",
            "              'values': []},\n",
            "             {'id': '48_r2',\n",
            "              'metadata': {'label': 0.0},\n",
            "              'score': 0.0837313682,\n",
            "              'values': []},\n",
            "             {'id': '123_l2',\n",
            "              'metadata': {'label': 3.0},\n",
            "              'score': 0.0832095519,\n",
            "              'values': []},\n",
            "             {'id': '123_l2_1.jpg',\n",
            "              'metadata': {'label': 3.0},\n",
            "              'score': 0.0799304619,\n",
            "              'values': []}],\n",
            " 'namespace': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_items_valid[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKrt50OTrFDy",
        "outputId": "b803e6a4-ec17-4e5e-ebdb-87798f5676f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('60_r1', '/content/drive/MyDrive/Fundus/DeepDRiD/regular-fundus-training/Images/60/60_r1.jpg', 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "MhJd6iP2n5vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_1 = []\n",
        "top_5 = []\n",
        "top_1_ids = []\n",
        "top_5_ids = []\n",
        "\n",
        "nbr_ids = []\n",
        "nbr_labels = []\n",
        "nbr_scores = []\n",
        "\n",
        "for i in range(len(valid_ds)):\n",
        "  q = valid_ds[i].tolist()\n",
        "  resp = index.query(q, top_k = 5, include_metadata = True)\n",
        "  nbrs_list = resp[\"matches\"]\n",
        "  top_1.append(int(nbrs_list[0][\"metadata\"][\"label\"]))\n",
        "  top_1_ids.append(nbrs_list[0][\"id\"])\n",
        "\n",
        "  gnd_val = file_items_valid[i][2]\n",
        "  top_5_flag = True\n",
        "\n",
        "  tmp_labels, tmp_ids, tmp_scores = [],[],[]\n",
        "  for nbr in nbrs_list:\n",
        "    if top_5_flag and int(nbr[\"metadata\"][\"label\"]) == gnd_val:\n",
        "      top_5.append(int(nbr[\"metadata\"][\"label\"]))\n",
        "      top_5_ids.append(nbr[\"id\"])\n",
        "      top_5_flag = False\n",
        "    tmp_labels.append(int(nbr[\"metadata\"][\"label\"]))\n",
        "    tmp_ids.append(nbr[\"id\"])\n",
        "    tmp_scores.append(nbr[\"score\"])\n",
        "\n",
        "  nbr_labels.append(tmp_labels)\n",
        "  nbr_ids.append(tmp_ids)\n",
        "  nbr_scores.append(tmp_scores)\n",
        "\n",
        "gnd_items = [file_items_valid[i][2] for i in range(len(file_items_valid))]"
      ],
      "metadata": {
        "id": "PzxLlcqxoF-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(gnd_items, top_1, digits = 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLU4GHzdoJzv",
        "outputId": "6b61dc98-a7f3-437f-921e-ee058a53db5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4286    0.9545    0.5915        22\n",
            "           1     0.0000    0.0000    0.0000         8\n",
            "           2     0.5000    0.1333    0.2105        15\n",
            "           3     0.5000    0.1000    0.1667        10\n",
            "           4     0.0000    0.0000    0.0000         3\n",
            "\n",
            "    accuracy                         0.4138        58\n",
            "   macro avg     0.2857    0.2376    0.1937        58\n",
            "weighted avg     0.3781    0.4138    0.3076        58\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(gnd_items, top_5, digits = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "ZgIKyjzHoNDG",
        "outputId": "cadb275f-64cc-4166-d34e-b4c70d8d23e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d3493de536d8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnd_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [58, 45]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NiinNk3soNVn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}